---
copyright:
  years: 1994, 2017, 2018, 2019
lastupdated: "2019-04-02"

keywords: hybrid, solution, latency, connected, milliseconds, high-capacity, performance, security, data, path, resiliency, PoPs, globe, infrastructure, backbone, traffic, workloads

subcollection: direct-link

---

{:shortdesc: .shortdesc}
{:new_window: target="_blank"}

# 了解等待时间
{: #understanding-latency}

_通过 {{site.data.keyword.cloud}} Direct Link 使用混合云：使工作负载在全球范围内运行更快_

{{site.data.keyword.cloud}} 在全球各地提供了具有 Direct Link 功能的数据中心。因此，使用 Direct Link 通过将 {{site.data.keyword.cloud_notm}} 链接到您的现有基础架构来创建混合云解决方案时，您的等待时间应该极短。

无论您是拥有在线商店，运行大数据解决方案，还是在网络上为员工设置对全球各地文件的访问权，您绝不会希望听到有人说在 Web 上页面装入速度慢或从数据库传输数据速度慢，因为这会影响您的销售工作或降低员工的工作效率。导致速度慢的原因可能是网络等待时间；网络等待时间测量的是在因特网上两个连接点之间的数据传输速度。您可以将网络等待时间视为一个数据包从一个位置转移到另一个位置所用的时间量。

在全球范围内，因特网的总体等待时间可能会有很大差异 - 这取决于数据必须物理上传输的距离、数据必须在服务提供商之间中继的次数、途中可用的带宽、在同一条路径中还有其他哪些数据在传输，以及其他多种变量。{{site.data.keyword.cloud_notm}} Direct Link 提供了确定性等待时间，相对于因特网，安全性更高，性能可预测。


## 了解网络等待时间
{: #understanding-network-latency}

作为最佳实践，每个网络提供商都希望向数量最多的客户提供最短的网络等待时间，而每个客户也都希望获得尽可能最短的等待时间。这是双方都期待的结果。

理论上，数据可以通过光纤网络电缆以光速传输，但出于上述所有原因，数据传输通常要慢得多。例如，如果特定网络连接已达到其带宽容量，那么数据包可能会暂时排队等待通过该路径传输。再例如，如果特定服务提供商的网络选择的并不是最佳网络路径，那么发送的数据包可能要传输几百或几千英里才能到达其目标！这些类型的延迟和绕路是导致网络等待时间更长的原因，同时导致数据传输速度更慢。

我们以毫秒（一秒等于 1,000 毫秒）为单位表示网络等待时间。在我们日常生活中，几毫秒可能无关紧要，但是在网页浏览或商业交易中，几毫秒往往成为决定性因素。例如，在金融行业的日常交易中，几毫秒可能意味着收益或损失相差数十亿美元。

## 最大限度缩短网络等待时间的常用方法
{: #common-approaches-that-minimize-network-latency}

考虑到我们的共同目标是最大限度缩短等待时间，因此限制可能影响数据移动速度的潜在变量数是有意义的。没有提供商能完全控制数据在因特网上的传输方式，但下面提供了用于最大限度缩短网络等待时间的一些最佳实践：

 * 在全球分布数据：不同位置的客户可以从在地理上靠近他们的位置拉取数据。因为数据离客户更近，所以减少了中继次数。数据传输距离越短，路由对性能产生重大影响的可能性越低。

 * 供应具有高容量网络端口的服务器：每秒可以在服务器上传输海量数据。如果由于端口完全饱和而导致数据包延迟，经过几毫秒时间，页面装入速度变慢，下载速度下降，用户会变得不满意。

 * 了解提供商如何路由流量：了解了有关如何将数据传输到全球各地客户的更多详细信息后，您可以就数据托管位置做出更好的决策。

## IBM Cloud 如何最大限度缩短网络等待时间
{: #how-ibm-cloud-minimizes-network-latency}

为了最大限度缩短等待时间，{{site.data.keyword.cloud_notm}} 采用了独特的方法来构建网络。我们的所有数据中心都连接到网络存在点 (PoP)，并且所有网络存在点都通过我们的全球主干网络相互连接。由于我们维护自己的全球主干网络，因此相比依赖其他提供商在地理区域之间移动数据，我们的网络运营团队可以更精准地控制网络路径和数据传输。
 
例如，如果柏林的一位 {{site.data.keyword.cloud_notm}} 客户要观看在达拉斯的 {{site.data.keyword.cloud_notm}} 服务器上托管的猫视频，那么组成该猫视频的数据包将通过我们的主干网络（由 {{site.data.keyword.cloud_notm}} 流量专用）传输到法兰克福，在法兰克福，这些数据包会发送给我们的一个对等连接或传输公用网络服务提供商，最终到达柏林的该用户。更好的一种情况是，如果客户使用的是 {{site.data.keyword.cloud_notm}} CDN 功能，那么数据包将从靠近客户的边缘服务器发送，而完全不需要从达拉斯发送。

如果没有全球主干网络，视频包就得发送到达拉斯的对等连接或传输公用网络提供商，然后由该提供商通过其网络来路由数据包，或者将数据包发送到网络中继段上的另一个提供商，然后数据包几经周折最终到达德国。在不使用全球主干网络的情况下，数据包也完全有可能以相同的网络等待时间从达拉斯到达柏林，但是如果没有全球主干网络，存在的变量更多；要想保证或预测总等待时间，难度要大得多。

{{site.data.keyword.cloud_notm}} 除了使用自己的全球主干网络，还将公共、专用和管理流量分段到不同的网络端口上。这意味着可传输不同类型的流量而互不干扰。

## 摘要：网络等待时间
{: #summary-network-latency}

客户希望尽快收到您的数据。数据在因特网上传输所用的时间称为网络等待时间。对数据网络路径的控制力越强，网络等待时间就越一致（并越短）。

* 通过 Direct Link，我们给予您对数据传输路径的控制力，使您的数据传输不会被其他流量中断或阻塞。

* {{site.data.keyword.cloud_notm}} 提供业界领先的服务提供商，从而提供高性能、高安全性和高弹性。

* {{site.data.keyword.cloud_notm}} 将继续在全球范围内增加网络存在点 (PoP)，使客户的数据更靠近客户，从而缩短等待时间，提高总体性能，以满足混合云工作负载的需求。

